<!DOCTYPE html>
<!-- saved from url=(0048)https://www.cnblogs.com/jin-liang/p/9551759.html -->
<html lang="zh-cn"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="referrer" content="origin">
    <meta property="og:description" content="引言 线性和逻辑回归通常是人们为机器学习和数据科学学习的第一个建模算法。 两者都很棒，因为它们易于使用和解释。 然而，它们固有的简单性也有一些缺点，在许多情况下它们并不是回归模型的最佳选择。 实际上有">
    <meta http-equiv="Cache-Control" content="no-transform">
    <meta http-equiv="Cache-Control" content="no-siteapp">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>五种回归方法的比较 - Jin_liang - 博客园</title>
    <link id="favicon" rel="shortcut icon" href="https://common.cnblogs.com/favicon.ico?v=20200522" type="image/x-icon">
    
    <link rel="stylesheet" href="./五种回归方法的比较 - Jin_liang - 博客园_files/blog-common.min.css">
    <link id="MainCss" rel="stylesheet" href="./五种回归方法的比较 - Jin_liang - 博客园_files/bundle-bluesky.min.css">
    
    <link id="mobile-style" media="only screen and (max-width: 767px)" type="text/css" rel="stylesheet" href="./五种回归方法的比较 - Jin_liang - 博客园_files/bundle-bluesky-mobile.min.css">
    
    <link type="application/rss+xml" rel="alternate" href="https://www.cnblogs.com/jin-liang/rss">
    <link type="application/rsd+xml" rel="EditURI" href="https://www.cnblogs.com/jin-liang/rsd.xml">
    <link type="application/wlwmanifest+xml" rel="wlwmanifest" href="https://www.cnblogs.com/jin-liang/wlwmanifest.xml">
    <script src="./五种回归方法的比较 - Jin_liang - 博客园_files/osd.js.下载"></script><script async="" src="./五种回归方法的比较 - Jin_liang - 博客园_files/analytics.js.下载"></script><script>
        var currentBlogId = 415892;
        var currentBlogApp = 'jin-liang';
        var cb_enable_mathjax = true;
        var isLogined = false;
        var isBlogOwner = false;
        var skinName = 'BlueSky';
        var visitorUserId = '';
    </script>
        <script>
            var currentPostDateAdded = '2018-09-05 09:54';
        </script>
    <script src="./五种回归方法的比较 - Jin_liang - 博客园_files/jquery-2.2.0.min.js.下载"></script>
    <script src="./五种回归方法的比较 - Jin_liang - 博客园_files/blog-common.min.js.下载"></script>
    <script type="text/x-mathjax-config;executed=true">
        MathJax.Hub.Config({
        tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']], processClass: 'math', processEscapes: true },
        TeX: {
        equationNumbers: { autoNumber: ['AMS'], useLabelIds: true },
        extensions: ['extpfeil.js', 'mediawiki-texvc.js'],
        Macros: {bm: "\\boldsymbol"}
        },
        'HTML-CSS': { linebreaks: { automatic: true } },
        SVG: { linebreaks: { automatic: true } }
        });
    </script>
    <script src="./五种回归方法的比较 - Jin_liang - 博客园_files/MathJax.js.下载"></script>
    
<style type="text/css">.MathJax_Hover_Frame {border-radius: .25em; -webkit-border-radius: .25em; -moz-border-radius: .25em; -khtml-border-radius: .25em; box-shadow: 0px 0px 15px #83A; -webkit-box-shadow: 0px 0px 15px #83A; -moz-box-shadow: 0px 0px 15px #83A; -khtml-box-shadow: 0px 0px 15px #83A; border: 1px solid #A6D ! important; display: inline-block; position: absolute}
.MathJax_Menu_Button .MathJax_Hover_Arrow {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 4px; -webkit-border-radius: 4px; -moz-border-radius: 4px; -khtml-border-radius: 4px; font-family: 'Courier New',Courier; font-size: 9px; color: #F0F0F0}
.MathJax_Menu_Button .MathJax_Hover_Arrow span {display: block; background-color: #AAA; border: 1px solid; border-radius: 3px; line-height: 0; padding: 4px}
.MathJax_Hover_Arrow:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_Hover_Arrow:hover span {background-color: #CCC!important}
</style><style type="text/css">#MathJax_About {position: fixed; left: 50%; width: auto; text-align: center; border: 3px outset; padding: 1em 2em; background-color: #DDDDDD; color: black; cursor: default; font-family: message-box; font-size: 120%; font-style: normal; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; border-radius: 15px; -webkit-border-radius: 15px; -moz-border-radius: 15px; -khtml-border-radius: 15px; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_About.MathJax_MousePost {outline: none}
.MathJax_Menu {position: absolute; background-color: white; color: black; width: auto; padding: 2px; border: 1px solid #CCCCCC; margin: 0; cursor: default; font: menu; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; z-index: 201; box-shadow: 0px 10px 20px #808080; -webkit-box-shadow: 0px 10px 20px #808080; -moz-box-shadow: 0px 10px 20px #808080; -khtml-box-shadow: 0px 10px 20px #808080; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
.MathJax_MenuItem {padding: 2px 2em; background: transparent}
.MathJax_MenuArrow {position: absolute; right: .5em; padding-top: .25em; color: #666666; font-size: .75em}
.MathJax_MenuActive .MathJax_MenuArrow {color: white}
.MathJax_MenuArrow.RTL {left: .5em; right: auto}
.MathJax_MenuCheck {position: absolute; left: .7em}
.MathJax_MenuCheck.RTL {right: .7em; left: auto}
.MathJax_MenuRadioCheck {position: absolute; left: 1em}
.MathJax_MenuRadioCheck.RTL {right: 1em; left: auto}
.MathJax_MenuLabel {padding: 2px 2em 4px 1.33em; font-style: italic}
.MathJax_MenuRule {border-top: 1px solid #CCCCCC; margin: 4px 1px 0px}
.MathJax_MenuDisabled {color: GrayText}
.MathJax_MenuActive {background-color: Highlight; color: HighlightText}
.MathJax_MenuDisabled:focus, .MathJax_MenuLabel:focus {background-color: #E8E8E8}
.MathJax_ContextMenu:focus {outline: none}
.MathJax_ContextMenu .MathJax_MenuItem:focus {outline: none}
#MathJax_AboutClose {top: .2em; right: .2em}
.MathJax_Menu .MathJax_MenuClose {top: -10px; left: -10px}
.MathJax_MenuClose {position: absolute; cursor: pointer; display: inline-block; border: 2px solid #AAA; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; font-family: 'Courier New',Courier; font-size: 24px; color: #F0F0F0}
.MathJax_MenuClose span {display: block; background-color: #AAA; border: 1.5px solid; border-radius: 18px; -webkit-border-radius: 18px; -moz-border-radius: 18px; -khtml-border-radius: 18px; line-height: 0; padding: 8px 0 6px}
.MathJax_MenuClose:hover {color: white!important; border: 2px solid #CCC!important}
.MathJax_MenuClose:hover span {background-color: #CCC!important}
.MathJax_MenuClose:hover:focus {outline: none}
</style><style type="text/css">.MathJax_Preview .MJXf-math {color: inherit!important}
</style><style type="text/css">.MJX_Assistive_MathML {position: absolute!important; top: 0; left: 0; clip: rect(1px, 1px, 1px, 1px); padding: 1px 0 0 0!important; border: 0!important; height: 1px!important; width: 1px!important; overflow: hidden!important; display: block!important; -webkit-touch-callout: none; -webkit-user-select: none; -khtml-user-select: none; -moz-user-select: none; -ms-user-select: none; user-select: none}
.MJX_Assistive_MathML.MJX_Assistive_MathML_Block {width: 100%!important}
</style><style type="text/css">#MathJax_Zoom {position: absolute; background-color: #F0F0F0; overflow: auto; display: block; z-index: 301; padding: .5em; border: 1px solid black; margin: 0; font-weight: normal; font-style: normal; text-align: left; text-indent: 0; text-transform: none; line-height: normal; letter-spacing: normal; word-spacing: normal; word-wrap: normal; white-space: nowrap; float: none; -webkit-box-sizing: content-box; -moz-box-sizing: content-box; box-sizing: content-box; box-shadow: 5px 5px 15px #AAAAAA; -webkit-box-shadow: 5px 5px 15px #AAAAAA; -moz-box-shadow: 5px 5px 15px #AAAAAA; -khtml-box-shadow: 5px 5px 15px #AAAAAA; filter: progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}
#MathJax_ZoomOverlay {position: absolute; left: 0; top: 0; z-index: 300; display: inline-block; width: 100%; height: 100%; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
#MathJax_ZoomFrame {position: relative; display: inline-block; height: 0; width: 0}
#MathJax_ZoomEventTrap {position: absolute; left: 0; top: 0; z-index: 302; display: inline-block; border: 0; padding: 0; margin: 0; background-color: white; opacity: 0; filter: alpha(opacity=0)}
</style><style type="text/css">.MathJax_Preview {color: #888}
#MathJax_Message {position: fixed; left: 1em; bottom: 1.5em; background-color: #E6E6E6; border: 1px solid #959595; margin: 0px; padding: 2px 8px; z-index: 102; color: black; font-size: 80%; width: auto; white-space: nowrap}
#MathJax_MSIE_Frame {position: absolute; top: 0; left: 0; width: 0px; z-index: 101; border: 0px; margin: 0px; padding: 0px}
.MathJax_Error {color: #CC0000; font-style: italic}
</style><style type="text/css">.MJXp-script {font-size: .8em}
.MJXp-right {-webkit-transform-origin: right; -moz-transform-origin: right; -ms-transform-origin: right; -o-transform-origin: right; transform-origin: right}
.MJXp-bold {font-weight: bold}
.MJXp-italic {font-style: italic}
.MJXp-scr {font-family: MathJax_Script,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-frak {font-family: MathJax_Fraktur,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-sf {font-family: MathJax_SansSerif,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-cal {font-family: MathJax_Caligraphic,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-mono {font-family: MathJax_Typewriter,'Times New Roman',Times,STIXGeneral,serif}
.MJXp-largeop {font-size: 150%}
.MJXp-largeop.MJXp-int {vertical-align: -.2em}
.MJXp-math {display: inline-block; line-height: 1.2; text-indent: 0; font-family: 'Times New Roman',Times,STIXGeneral,serif; white-space: nowrap; border-collapse: collapse}
.MJXp-display {display: block; text-align: center; margin: 1em 0}
.MJXp-math span {display: inline-block}
.MJXp-box {display: block!important; text-align: center}
.MJXp-box:after {content: " "}
.MJXp-rule {display: block!important; margin-top: .1em}
.MJXp-char {display: block!important}
.MJXp-mo {margin: 0 .15em}
.MJXp-mfrac {margin: 0 .125em; vertical-align: .25em}
.MJXp-denom {display: inline-table!important; width: 100%}
.MJXp-denom > * {display: table-row!important}
.MJXp-surd {vertical-align: top}
.MJXp-surd > * {display: block!important}
.MJXp-script-box > *  {display: table!important; height: 50%}
.MJXp-script-box > * > * {display: table-cell!important; vertical-align: top}
.MJXp-script-box > *:last-child > * {vertical-align: bottom}
.MJXp-script-box > * > * > * {display: block!important}
.MJXp-mphantom {visibility: hidden}
.MJXp-munderover, .MJXp-munder {display: inline-table!important}
.MJXp-over {display: inline-block!important; text-align: center}
.MJXp-over > * {display: block!important}
.MJXp-munderover > *, .MJXp-munder > * {display: table-row!important}
.MJXp-mtable {vertical-align: .25em; margin: 0 .125em}
.MJXp-mtable > * {display: inline-table!important; vertical-align: middle}
.MJXp-mtr {display: table-row!important}
.MJXp-mtd {display: table-cell!important; text-align: center; padding: .5em 0 0 .5em}
.MJXp-mtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-mlabeledtr {display: table-row!important}
.MJXp-mlabeledtr > .MJXp-mtd:first-child {padding-left: 0}
.MJXp-mlabeledtr:first-child > .MJXp-mtd {padding-top: 0}
.MJXp-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 1px 3px; font-style: normal; font-size: 90%}
.MJXp-scale0 {-webkit-transform: scaleX(.0); -moz-transform: scaleX(.0); -ms-transform: scaleX(.0); -o-transform: scaleX(.0); transform: scaleX(.0)}
.MJXp-scale1 {-webkit-transform: scaleX(.1); -moz-transform: scaleX(.1); -ms-transform: scaleX(.1); -o-transform: scaleX(.1); transform: scaleX(.1)}
.MJXp-scale2 {-webkit-transform: scaleX(.2); -moz-transform: scaleX(.2); -ms-transform: scaleX(.2); -o-transform: scaleX(.2); transform: scaleX(.2)}
.MJXp-scale3 {-webkit-transform: scaleX(.3); -moz-transform: scaleX(.3); -ms-transform: scaleX(.3); -o-transform: scaleX(.3); transform: scaleX(.3)}
.MJXp-scale4 {-webkit-transform: scaleX(.4); -moz-transform: scaleX(.4); -ms-transform: scaleX(.4); -o-transform: scaleX(.4); transform: scaleX(.4)}
.MJXp-scale5 {-webkit-transform: scaleX(.5); -moz-transform: scaleX(.5); -ms-transform: scaleX(.5); -o-transform: scaleX(.5); transform: scaleX(.5)}
.MJXp-scale6 {-webkit-transform: scaleX(.6); -moz-transform: scaleX(.6); -ms-transform: scaleX(.6); -o-transform: scaleX(.6); transform: scaleX(.6)}
.MJXp-scale7 {-webkit-transform: scaleX(.7); -moz-transform: scaleX(.7); -ms-transform: scaleX(.7); -o-transform: scaleX(.7); transform: scaleX(.7)}
.MJXp-scale8 {-webkit-transform: scaleX(.8); -moz-transform: scaleX(.8); -ms-transform: scaleX(.8); -o-transform: scaleX(.8); transform: scaleX(.8)}
.MJXp-scale9 {-webkit-transform: scaleX(.9); -moz-transform: scaleX(.9); -ms-transform: scaleX(.9); -o-transform: scaleX(.9); transform: scaleX(.9)}
.MathJax_PHTML .noError {vertical-align: ; font-size: 90%; text-align: left; color: black; padding: 1px 3px; border: 1px solid}
</style><script src="./五种回归方法的比较 - Jin_liang - 博客园_files/pubads_impl_2020090901.js.下载" async=""></script><link rel="preload" href="./五种回归方法的比较 - Jin_liang - 博客园_files/f(5).txt" as="script"><script type="text/javascript" src="./五种回归方法的比较 - Jin_liang - 博客园_files/f(5).txt"></script><link rel="prefetch" href="https://d28eda45ae374e2f17fd0e99026b1f23.safeframe.googlesyndication.com/safeframe/1-0-37/html/container.html"><link rel="prefetch" href="https://tpc.googlesyndication.com/safeframe/1-0-37/html/container.html"></head>
<body><div id="MathJax_Message" style="display: none;"></div>
    <a name="top"></a>
    
    
<!--done-->
<div id="home">
<div id="header">
	<div id="blogTitle">
        <a id="lnkBlogLogo" href="https://www.cnblogs.com/jin-liang/"><img id="blogLogo" src="./五种回归方法的比较 - Jin_liang - 博客园_files/logo.gif" alt="返回主页"></a>		
		
<!--done-->
<h1><a id="Header1_HeaderTitle" class="headermaintitle HeaderMainTitle" href="https://www.cnblogs.com/jin-liang/">Jin_liang</a>
</h1>
<h2>

</h2>




		
	</div><!--end: blogTitle 博客的标题和副标题 -->
	<div id="navigator">
		
<ul id="navList">
<li><a id="blog_nav_sitehome" class="menu" href="https://www.cnblogs.com/">
博客园</a>
</li>
<li>
<a id="blog_nav_myhome" class="menu" href="https://www.cnblogs.com/jin-liang/">
首页</a>
</li>
<li>

<a id="blog_nav_newpost" class="menu" href="https://i.cnblogs.com/EditPosts.aspx?opt=1">
新随笔</a>
</li>
<li>
<a id="blog_nav_contact" class="menu" href="https://msg.cnblogs.com/send/Jin_liang">
联系</a></li>
<li>
<a id="blog_nav_rss" class="menu" href="javascript:void(0)" data-rss="https://www.cnblogs.com/jin-liang/rss/">
订阅</a>
<!--<partial name="./Shared/_XmlLink.cshtml" model="Model" /></li>--></li>
<li>
<a id="blog_nav_admin" class="menu" href="https://i.cnblogs.com/">
管理</a>
</li>
</ul>


		<div class="blogStats">
			
			<span id="stats_post_count">随笔 - 
42&nbsp; </span>
<span id="stats_article_count">文章 - 
0&nbsp; </span>
<span id="stats-comment_count">评论 - 
8</span>

			
		</div><!--end: blogStats -->
	</div><!--end: navigator 博客导航栏 -->
</div><!--end: header 头部 -->

<div id="main">
	<div id="mainContent">
	<div class="forFlow">
		<div id="post_detail">
    <!--done-->
    <div id="topics">
        <div class="post">
            <h1 class="postTitle">
                
<a id="cb_post_title_url" class="postTitle2 vertical-middle" href="https://www.cnblogs.com/jin-liang/p/9551759.html">
    <span>五种回归方法的比较</span>
    


</a>

            </h1>
            <div class="clear"></div>
            <div class="postBody">
                
<div id="cnblogs_post_body" class="blogpost-body">
    <p>&nbsp;</p>
<p><span style="font-size: 18px;">　引言</span></p>
<p><span style="font-size: 18px;">　线性和逻辑回归通常是人们为机器学习和数据科学学习的第一个建模算法。 两者都很棒，因为它们易于使用和解释。 然而，它们固有的简单性也有一些缺点，在许多情况下它们并不是回归模型的最佳选择。 实际上有几种不同类型的回归，每种都有自己的优点和缺点。</span></p>
<p><span style="font-size: 18px;">　　在这篇文章中，我们将讨论5种最常见的回归算法及其属性，同时评估他们的性能。 最后，希望让您更全面地了解回归模型！</span></p>
<p><span style="font-size: 18px;">　　目录</span></p>
<ul>
<li><span style="font-size: 18px;">线性回归</span></li>
<li><span style="font-size: 18px;">多项式回归</span></li>
<li><span style="font-size: 18px;">岭回归</span></li>
<li><span style="font-size: 18px;">套索回归</span></li>
<li><span style="font-size: 18px;">弹性网络回归</span></li>
</ul>
<hr>
<h1>线性回归（Linear Regression）</h1>
<p><span style="font-size: 18px;">　　回归是一种用于建模和分析变量之间关系的技术，通常是它们如何结合并且与一起产生特定结果相关。 线性回归指的是完全由线性变量组成的回归模型。 从简单的情况开始，单变量线性回归是一种技术，用于使用线性模型对单个输入自变量和输出因变量之间的关系进行建模。</span></p>
<p><span style="font-size: 18px;">　　更一般的情况是多变量线性回归，其中为多个独立输入变量（特征变量）和输出因变量之间的关系创建模型。 模型保持线性，输出是输入变量的线性组合。 我们可以建模多变量线性回归，如下所示：</span></p>
<p><img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180828235210103-1309136038.png" alt=""></p>
<p><span style="font-size: 18px;">　　其中a_n是系数，X_n是变量，b是偏差。 我们可以看到，此函数不包含任何非线性，因此仅适用于对线性可分离数据进行建模，因为我们只是使用系数权重a_n来加权每个特征变量X_n的重要性。&nbsp;</span></p>
<p>&nbsp;</p>
<p><span style="font-size: 18px;">关于线性回归的几个关键点：</span></p>
<p>&nbsp;</p>
<ul>
<li><span style="font-size: 18px;">建模快速简便，当要建模的关系不是非常复杂且没有大量数据时尤其有用。</span></li>
<li><span style="font-size: 18px;">非常直观地理解和解释。</span></li>
<li><span style="font-size: 18px;">线性回归对异常值非常敏感。</span></li>
</ul>
<p>&nbsp;</p>
<p>&nbsp;<span style="font-size: 18px;">python实例：</span></p>
<p>&nbsp;</p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_384948" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">import</code> <code class="python plain">numpy as np</code></div><div class="line number2 index1 alt1"><code class="python keyword">import</code> <code class="python plain">pandas as pd</code></div><div class="line number3 index2 alt2"><code class="python keyword">from</code> <code class="python plain">sklearn </code><code class="python keyword">import</code> <code class="python plain">datasets</code></div><div class="line number4 index3 alt1"><code class="python keyword">from</code> <code class="python plain">sklearn </code><code class="python keyword">import</code> <code class="python plain">metrics</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="python plain">data</code><code class="python keyword">=</code><code class="python plain">datasets.load_boston()</code><code class="python comments"># load data</code></div><div class="line number7 index6 alt2">&nbsp;</div><div class="line number8 index7 alt1"><code class="python comments">#定义评估函数</code></div><div class="line number9 index8 alt2"><code class="python keyword">def</code> <code class="python plain">evaluation(y_true,y_pred,index_name</code><code class="python keyword">=</code><code class="python plain">[</code><code class="python string">'OLS'</code><code class="python plain">]):</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">df</code><code class="python keyword">=</code><code class="python plain">pd.DataFrame(index</code><code class="python keyword">=</code><code class="python plain">[index_name],columns</code><code class="python keyword">=</code><code class="python plain">[</code><code class="python string">'平均绝对误差'</code><code class="python plain">,</code><code class="python string">'均方误差'</code><code class="python plain">,</code><code class="python string">'r2'</code><code class="python plain">])</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">df[</code><code class="python string">'平均绝对误差'</code><code class="python plain">]</code><code class="python keyword">=</code><code class="python plain">metrics.mean_absolute_error(y_true, y_pred).</code><code class="python functions">round</code><code class="python plain">(</code><code class="python value">4</code><code class="python plain">)</code></div><div class="line number12 index11 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">df[</code><code class="python string">'均方误差'</code><code class="python plain">]</code><code class="python keyword">=</code><code class="python plain">metrics.mean_squared_error(y_true,y_pred)</code></div><div class="line number13 index12 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">df[</code><code class="python string">'r2'</code><code class="python plain">]</code><code class="python keyword">=</code><code class="python plain">metrics.r2_score(y_true,y_pred)</code></div><div class="line number14 index13 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">return</code> <code class="python plain">df</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　</p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_323224" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">df</code><code class="python keyword">=</code><code class="python plain">pd.DataFrame(data.data,columns</code><code class="python keyword">=</code><code class="python plain">data.feature_names)</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python plain">target</code><code class="python keyword">=</code><code class="python plain">pd.DataFrame(data.target,columns</code><code class="python keyword">=</code><code class="python plain">[</code><code class="python string">'MEDV'</code><code class="python plain">])</code></div></div></td></tr></tbody></table></div></div>
</div>
<p><span style="font-size: 18px;">　　简单的可视化分析：</span></p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_344034" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">import</code> <code class="python plain">matplotlib.pyplot as plt</code></div><div class="line number2 index1 alt1"><code class="python keyword">import</code> <code class="python plain">seaborn as sns</code></div><div class="line number3 index2 alt2"><code class="python plain">sns.</code><code class="python functions">set</code><code class="python plain">(style</code><code class="python keyword">=</code><code class="python string">"whitegrid"</code><code class="python plain">, color_codes</code><code class="python keyword">=</code><code class="python color1">True</code><code class="python plain">)</code></div><div class="line number4 index3 alt1">&nbsp;</div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="python plain">g</code><code class="python keyword">=</code><code class="python plain">sns.pairplot(data[</code><code class="python functions">list</code><code class="python plain">(data.columns)[:</code><code class="python value">5</code><code class="python plain">]], hue</code><code class="python keyword">=</code><code class="python string">'ZN'</code><code class="python plain">,palette</code><code class="python keyword">=</code><code class="python string">"husl"</code><code class="python plain">,diag_kind</code><code class="python keyword">=</code><code class="python string">"hist"</code><code class="python plain">,size</code><code class="python keyword">=</code><code class="python value">2.5</code><code class="python plain">)</code></div><div class="line number7 index6 alt2"><code class="python keyword">for</code> <code class="python plain">ax </code><code class="python keyword">in</code> <code class="python plain">g.axes.flat: </code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">plt.setp(ax.get_xticklabels(), rotation</code><code class="python keyword">=</code><code class="python value">45</code><code class="python plain">)</code></div><div class="line number9 index8 alt2"><code class="python plain">plt.tight_layout()</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　　<img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905212531559-649798200.png" alt=""></p>
<p><span style="font-size: 18px;">特征的相关系数图：</span></p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_824408" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">cm </code><code class="python keyword">=</code> <code class="python plain">np.corrcoef(data[</code><code class="python functions">list</code><code class="python plain">(data.columns)[:</code><code class="python value">5</code><code class="python plain">]].values.T)&nbsp;&nbsp; </code><code class="python comments">#corrcoef方法按行计算皮尔逊相关系数,cm是对称矩阵</code></div><div class="line number2 index1 alt1"><code class="python comments">#使用np.corrcoef(a)可计算行与行之间的相关系数,np.corrcoef(a,rowvar=0)用于计算各列之间的相关系数,输出为相关系数矩阵。</code></div><div class="line number3 index2 alt2"><code class="python plain">sns.</code><code class="python functions">set</code><code class="python plain">(font_scale</code><code class="python keyword">=</code><code class="python value">1.5</code><code class="python plain">)&nbsp;&nbsp; </code><code class="python comments">#font_scale设置字体大小</code></div><div class="line number4 index3 alt1"><code class="python plain">cols</code><code class="python keyword">=</code><code class="python functions">list</code><code class="python plain">(data.columns)[:</code><code class="python value">5</code><code class="python plain">]</code></div><div class="line number5 index4 alt2"><code class="python plain">hm </code><code class="python keyword">=</code> <code class="python plain">sns.heatmap(cm,cbar</code><code class="python keyword">=</code><code class="python color1">True</code><code class="python plain">,annot</code><code class="python keyword">=</code><code class="python color1">True</code><code class="python plain">,square</code><code class="python keyword">=</code><code class="python color1">True</code><code class="python plain">,fmt</code><code class="python keyword">=</code><code class="python string">'.2f'</code><code class="python plain">,annot_kws</code><code class="python keyword">=</code><code class="python plain">{</code><code class="python string">'size'</code><code class="python plain">: </code><code class="python value">15</code><code class="python plain">},yticklabels</code><code class="python keyword">=</code><code class="python plain">cols,xticklabels</code><code class="python keyword">=</code><code class="python plain">cols)</code></div><div class="line number6 index5 alt1"><code class="python comments"># plt.tight_layout()</code></div><div class="line number7 index6 alt2"><code class="python comments"># plt.savefig('./figures/corr_mat.png', dpi=300)</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　　<img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905212639015-1313580620.png" alt=""></p>
<p><span style="font-size: 18px;">&nbsp;用statsmodels模块的OLS</span></p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_656197" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">import</code> <code class="python plain">statsmodels.api as sm</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python plain">X</code><code class="python keyword">=</code><code class="python plain">df[df.columns].values</code></div><div class="line number4 index3 alt1"><code class="python plain">y</code><code class="python keyword">=</code><code class="python plain">target[</code><code class="python string">'MEDV'</code><code class="python plain">].values</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="python comments">#add constant</code></div><div class="line number7 index6 alt2"><code class="python plain">X</code><code class="python keyword">=</code><code class="python plain">sm.add_constant(X)</code></div><div class="line number8 index7 alt1">&nbsp;</div><div class="line number9 index8 alt2"><code class="python comments"># build model</code></div><div class="line number10 index9 alt1"><code class="python plain">model</code><code class="python keyword">=</code><code class="python plain">sm.OLS(y,X).fit()</code></div><div class="line number11 index10 alt2">&nbsp;</div><div class="line number12 index11 alt1"><code class="python plain">prediction</code><code class="python keyword">=</code><code class="python plain">model.predict(X)</code></div><div class="line number13 index12 alt2">&nbsp;</div><div class="line number14 index13 alt1"><code class="python functions">print</code><code class="python plain">(model.summary())</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　<span style="font-size: 18px;">　也可以用sklearn模块：</span></p>
<p>&nbsp;</p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_369162" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">from</code> <code class="python plain">sklearn </code><code class="python keyword">import</code> <code class="python plain">linear_model</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python plain">lm </code><code class="python keyword">=</code> <code class="python plain">linear_model.LinearRegression()</code></div><div class="line number4 index3 alt1"><code class="python plain">model </code><code class="python keyword">=</code> <code class="python plain">lm.fit(X,y)</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="python plain">y_pred </code><code class="python keyword">=</code> <code class="python plain">lm.predict(X)</code></div><div class="line number7 index6 alt2">&nbsp;</div><div class="line number8 index7 alt1"><code class="python plain">lm.score(X,y)</code></div><div class="line number9 index8 alt2">&nbsp;</div><div class="line number10 index9 alt1"><code class="python comments">#系数</code></div><div class="line number11 index10 alt2"><code class="python plain">lm.coef_</code></div><div class="line number12 index11 alt1"><code class="python comments">#截距</code></div><div class="line number13 index12 alt2"><code class="python plain">lm.intercept_&lt;br&gt;&lt;br&gt;evaluation(y,y_pred)</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　　<img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905213046099-1990029922.png" alt=""></p>
<h1>多项式回归（Polynomial Regression）</h1>
<p><span style="font-size: 18px;">&nbsp;　　当我们想要创建一个适合处理非线性可分数据的模型时，我们需要使用多项式回归。 在这种回归技术中，最佳拟合线不是直线。 它是一条适合数据点的曲线。 对于多项式回归，一些自变量的幂大于1.例如：</span></p>
<p><img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905213235901-432154052.png" alt=""></p>
<p><span style="font-size: 18px;">我们可以让一些变量具有指数，其他变量没有指数，并且还为每个变量选择我们想要的精确指数。 但是，选择每个变量的精确指数自然需要了解数据如何与输出相关。</span></p>
<p><span style="font-size: 18px;">note：</span></p>
<ul>
<li><span style="font-size: 18px;">能够建模非线性可分离数据; 线性回归不能做到这一点。 它通常更灵活，可以建立一些相当复杂的关系。</span></li>
<li><span style="font-size: 18px;">完全控制特征变量的建模（指定要设置）。</span></li>
<li><span style="font-size: 18px;">需要仔细设计。 需要一些数据知识才能选择最佳指数。</span></li>
<li><span style="font-size: 18px;">如果指数选择不当，容易过度拟合</span>。</li>
</ul>
<p><span style="font-size: 18px;">python实例：</span></p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_440035" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">from</code> <code class="python plain">sklearn.preprocessing </code><code class="python keyword">import</code> <code class="python plain">PolynomialFeatures</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python plain">poly_reg </code><code class="python keyword">=</code> <code class="python plain">PolynomialFeatures(degree </code><code class="python keyword">=</code> <code class="python value">4</code><code class="python plain">)</code></div><div class="line number4 index3 alt1"><code class="python plain">X_Poly </code><code class="python keyword">=</code> <code class="python plain">poly_reg.fit_transform(X)</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="python plain">lin_reg_2 </code><code class="python keyword">=</code><code class="python plain">linear_model.LinearRegression()</code></div><div class="line number7 index6 alt2"><code class="python plain">lin_reg_2.fit(X_Poly, y)</code></div><div class="line number8 index7 alt1">&nbsp;</div><div class="line number9 index8 alt2">&nbsp;</div><div class="line number10 index9 alt1"><code class="python plain">y_pred</code><code class="python keyword">=</code><code class="python plain">lin_reg_2.predict(poly_reg.fit_transform(X))</code></div><div class="line number11 index10 alt2">&nbsp;</div><div class="line number12 index11 alt1"><code class="python plain">evaluation(y,y_pred,index_name</code><code class="python keyword">=</code><code class="python plain">[</code><code class="python string">'poly_reg'</code><code class="python plain">])</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　　<img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905213647915-511405346.png" alt=""></p>
<p><span style="font-size: 18px;">可以看到，误差很小，r2很大，模型已经过拟合。</span></p>
<h1>岭回归（ride regression）</h1>
<p><span style="font-size: 18px;">　　在特征变量之间存在高共线性的情况下，标准线性或多项式回归将失败。 共线性是独立变量之间存在近线性关系。 高共线性的存在可以通过几种不同的方式确定：</span></p>
<ul>
<li><span style="font-size: 18px;">即使理论上该变量应该与Y高度相关，回归系数也不显着。</span></li>
<li><span style="font-size: 18px;">添加或删除X特征变量时，回归系数会发生显着变化。</span></li>
<li><span style="font-size: 18px;">X特征变量具有高成对相关性（检查相关矩阵）。</span></li>
</ul>
<p><span style="font-size: 18px;">我们首先可以看一下标准线性回归的优化函数，以获得有关岭回归如何帮助的一些见解：</span></p>
<p>&nbsp;<img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905213929727-1669376198.png" alt=""></p>
<p><span style="font-size: 18px;">其中X代表特征变量，w代表权重，y代表实际值。 岭回归是一种补救措施，用于缓解回归模型中预测变量之间的共线性。 由于特征变量存在共线性，因此最终回归模型具有高方差。</span></p>
<p><span style="font-size: 18px;">为了缓解这个问题，Ridge Regression为变量添加了一个小的平方偏差因子：</span></p>
<p><img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905214138168-745965012.png" alt=""></p>
<p><span style="font-size: 18px;">在模型中引入少量偏差，但大大减小了方差。</span></p>
<p><span style="font-size: 18px;">note：</span></p>
<ul>
<li><span style="font-size: 18px;">该回归的假设与最小二乘回归类似，但没有正态性假设。</span></li>
<li><span style="font-size: 18px;">它会缩小系数的值，但不会达到零，这表明没有特征选择功能</span></li>
</ul>
<p><span style="font-size: 18px;">&nbsp;python实例：</span></p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_931752" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">from</code> <code class="python plain">sklearn.linear_model </code><code class="python keyword">import</code> <code class="python plain">Ridge</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python plain">ridge_reg </code><code class="python keyword">=</code> <code class="python plain">Ridge(alpha</code><code class="python keyword">=</code><code class="python value">1</code><code class="python plain">, solver</code><code class="python keyword">=</code><code class="python string">"cholesky"</code><code class="python plain">)</code></div><div class="line number4 index3 alt1"><code class="python plain">ridge_reg.fit(X, y)</code></div><div class="line number5 index4 alt2">&nbsp;</div><div class="line number6 index5 alt1"><code class="python plain">y_pred</code><code class="python keyword">=</code><code class="python plain">ridge_reg.predict(X</code></div><div class="line number7 index6 alt2">&nbsp;</div><div class="line number8 index7 alt1"><code class="python plain">evaluation(y,y_pred,index_name</code><code class="python keyword">=</code><code class="python string">'ridge_reg'</code><code class="python plain">)</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　　<img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905214410672-498016290.png" alt=""></p>
<h1>套索回归（lasso regression）</h1>
<p><span style="font-size: 18px;">　　套索回归与岭回归非常相似，因为两种技术都具有相同的前提。 我们再次为回归优化函数添加一个偏置项，以减少共线性的影响，从而减小模型方差。 然而，不是使用像岭回归那样的平方偏差，而套索回归使用绝对值偏差：</span></p>
<p><span style="font-size: 18px;"><img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905214547833-521187978.png" alt=""></span></p>
<p><span style="font-size: 18px;">Ridge和Lasso回归之间存在一些差异，这些差异基本上可以回归到L2和L1正则化的属性差异：</span></p>
<ul>
<li><span style="font-size: 18px;">内置特征选择：经常被提及为L1范数的有用属性，而L2范数则不然。这实际上是L1范数的结果，它倾向于产生稀疏系数。例如，假设模型有100个系数，但只有10个系数具有非零系数，这实际上是说“其他90个预测变量在预测目标值方面毫无用处”。 L2范数产生非稀疏系数，因此不具有此属性。因此，可以说Lasso回归做了一种“参数选择”，因为未选择的特征变量的总权重为0。</span></li>
<li><span style="font-size: 18px;">稀疏性：指矩阵（或向量）中只有极少数条目为非零。 L1范数具有产生许多具有零值的系数或具有很少大系数的非常小的值的特性。这与Lasso执行一种特征选择的前一点相关联。</span></li>
<li><span style="font-size: 18px;">计算效率：L1范数没有解析解，但L2有。在计算上可以有效地计算L2范数解。然而，L1范数具有稀疏性属性，允许它与稀疏算法一起使用，这使得计算在计算上更有效。</span></li>
</ul>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_994793" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">from</code> <code class="python plain">sklearn.linear_model </code><code class="python keyword">import</code> <code class="python plain">Lasso</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python plain">lasso_reg </code><code class="python keyword">=</code> <code class="python plain">Lasso(alpha</code><code class="python keyword">=</code><code class="python value">0.1</code><code class="python plain">)</code></div><div class="line number4 index3 alt1"><code class="python plain">lasso_reg.fit(X, y)</code></div><div class="line number5 index4 alt2"><code class="python plain">y_pred</code><code class="python keyword">=</code><code class="python plain">lasso_reg.predict(X)</code></div><div class="line number6 index5 alt1"><code class="python plain">evaluation(y,y_pred,index_name</code><code class="python keyword">=</code><code class="python string">'lasso_reg'</code><code class="python plain">)</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　　<img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905214942894-919554761.png" alt=""></p>
<h1>弹性网络回归（ElasticNet Regression）</h1>
<p><span style="font-size: 18px;">　　ElasticNet是Lasso和Ridge Regression技术的混合体。 它使用L1和L2正则化来考虑两种技术的影响：</span></p>
<p><span style="font-size: 18px;"><img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905215041173-1740503604.png" alt=""></span></p>
<p><span style="font-size: 18px;">在Lasso和Ridge之间进行权衡的一个实际优势是：它允许Elastic-Net在旋转下继承Ridge的一些稳定性。</span></p>
<p><span style="font-size: 18px;">note：</span></p>
<ul>
<li><span style="font-size: 18px;">它在高度相关的变量的情况下鼓励群体效应，而不是像Lasso那样将其中的一些归零。</span></li>
<li><span style="font-size: 18px;">所选变量的数量没有限制。</span></li>
</ul>
<p><span style="font-size: 18px;">&nbsp;python实例：</span></p>
<div class="cnblogs_Highlighter sh-gutter">
<div><div id="highlighter_63922" class="syntaxhighlighter  python"><div class="toolbar"><span><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" class="toolbar_item command_help help">?</a></span></div><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">enet_reg </code><code class="python keyword">=</code> <code class="python plain">linear_model.ElasticNet(l1_ratio</code><code class="python keyword">=</code><code class="python value">0.7</code><code class="python plain">)</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python plain">enet_reg.fit(X,y)</code></div><div class="line number4 index3 alt1">&nbsp;</div><div class="line number5 index4 alt2"><code class="python plain">y_pred</code><code class="python keyword">=</code><code class="python plain">enet_reg.predict(X)</code></div><div class="line number6 index5 alt1"><code class="python plain">evaluation(y,y_pred,index_name</code><code class="python keyword">=</code><code class="python string">'enet_reg '</code><code class="python plain">)</code></div></div></td></tr></tbody></table></div></div>
</div>
<p>　　<img src="./五种回归方法的比较 - Jin_liang - 博客园_files/1345004-20180905215233013-1983314124.png" alt=""></p>
<h1>小结：</h1>
<p><span style="font-size: 18px;">　　这篇文章简单总结了5种常见类型的回归及其属性。 所有这些回归正则化方法（Lasso，Ridge和ElasticNet）在数据集中变量之间的高维度和多重共线性的情况下都能很好地工作。 希望对大家有帮助！</span></p>
<p>&nbsp;</p>
</div>
<div id="MySignature"></div>
<div class="clear"></div>
<div id="blog_post_info_block"><div id="BlogPostCategory">
    分类: 
            <a href="https://www.cnblogs.com/jin-liang/category/1197005.html" target="_blank">机器学习之路</a></div>


    <div id="blog_post_info">
<div id="green_channel">
        <a href="javascript:void(0);" id="green_channel_digg" onclick="DiggIt(9551759,cb_blogId,1);green_channel_success(this,&#39;谢谢推荐！&#39;);">好文要顶</a>
        <a id="green_channel_follow" onclick="follow(&#39;e7b8b72d-1c91-4228-9a4a-08d581a6bd57&#39;);" href="javascript:void(0);">关注我</a>
    <a id="green_channel_favorite" onclick="AddToWz(cb_entryId);return false;" href="javascript:void(0);">收藏该文</a>
    <a id="green_channel_weibo" href="javascript:void(0);" title="分享至新浪微博" onclick="ShareToTsina()"><img src="./五种回归方法的比较 - Jin_liang - 博客园_files/icon_weibo_24.png" alt=""></a>
    <a id="green_channel_wechat" href="javascript:void(0);" title="分享至微信" onclick="shareOnWechat()"><img src="./五种回归方法的比较 - Jin_liang - 博客园_files/wechat.png" alt=""></a>
</div>
<div id="author_profile">
    <div id="author_profile_info" class="author_profile_info">
            <a href="https://home.cnblogs.com/u/jin-liang/" target="_blank"><img src="./五种回归方法的比较 - Jin_liang - 博客园_files/sample_face.gif" class="author_avatar" alt=""></a>
        <div id="author_profile_detail" class="author_profile_info">
            <a href="https://home.cnblogs.com/u/jin-liang/">Jin_liang</a><br>
            <a href="https://home.cnblogs.com/u/jin-liang/followees/">关注 - 1</a><br>
            <a href="https://home.cnblogs.com/u/jin-liang/followers/">粉丝 - 31</a>
        </div>
    </div>
    <div class="clear"></div>
    <div id="author_profile_honor"></div>
    <div id="author_profile_follow">
                <a href="javascript:void(0);" onclick="follow(&#39;e7b8b72d-1c91-4228-9a4a-08d581a6bd57&#39;);return false;">+加关注</a>
    </div>
</div>
<div id="div_digg">
    <div class="diggit" onclick="votePost(9551759,&#39;Digg&#39;)">
        <span class="diggnum" id="digg_count">1</span>
    </div>
    <div class="buryit" onclick="votePost(9551759,&#39;Bury&#39;)">
        <span class="burynum" id="bury_count">0</span>
    </div>
    <div class="clear"></div>
    <div class="diggword" id="digg_tips">
    </div>
</div>

<script type="text/javascript">
    currentDiggType = 0;
</script></div>
    <div class="clear"></div>
    <div id="post_next_prev">

    <a href="https://www.cnblogs.com/jin-liang/p/9539622.html" class="p_n_p_prefix">« </a> 上一篇：    <a href="https://www.cnblogs.com/jin-liang/p/9539622.html" title="发布于 2018-08-27 14:58">如何判别模型的优劣？</a>
    <br>
    <a href="https://www.cnblogs.com/jin-liang/p/9595477.html" class="p_n_p_prefix">» </a> 下一篇：    <a href="https://www.cnblogs.com/jin-liang/p/9595477.html" title="发布于 2018-09-06 20:00">k近邻聚类简介</a>

</div>
</div>
            </div>
            <div class="postDesc">posted @ 
<span id="post-date">2018-09-05 21:54</span>&nbsp;
<a href="https://www.cnblogs.com/jin-liang/">Jin_liang</a>&nbsp;
阅读(<span id="post_view_count">11562</span>)&nbsp;
评论(<span id="post_comment_count">0</span>)&nbsp;
<a href="https://i.cnblogs.com/EditPosts.aspx?postid=9551759" rel="nofollow">编辑</a>&nbsp;
<a href="javascript:void(0)" onclick="AddToWz(9551759);return false;">收藏</a></div>
        </div>
	    
	    
    </div><!--end: topics 文章、评论容器-->
</div>
<script src="./五种回归方法的比较 - Jin_liang - 博客园_files/highlight.min.js.下载"></script>
<script>markdown_highlight();</script>
<script>
    var allowComments = true, cb_blogId = 415892, cb_blogApp = 'jin-liang', cb_blogUserGuid = 'e7b8b72d-1c91-4228-9a4a-08d581a6bd57';
    var cb_entryId = 9551759, cb_entryCreatedDate = '2018-09-05 21:54', cb_postType = 1;
    loadViewCount(cb_entryId);
</script><a name="!comments"></a>
<div id="blog-comments-placeholder"></div>
<script>
    var commentManager = new blogCommentManager();
    commentManager.renderComments(0);
</script>
<div id="comment_form" class="commentform">
    <a name="commentform"></a>
    <div id="divCommentShow"></div>
    <div id="comment_nav"><span id="span_refresh_tips"></span><a href="javascript:void(0);" onclick="return RefreshCommentList();" id="lnk_RefreshComments" runat="server" clientidmode="Static">刷新评论</a><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#" onclick="return RefreshPage();">刷新页面</a><a href="https://www.cnblogs.com/jin-liang/p/9551759.html#top">返回顶部</a></div>
    <div id="comment_form_container" style="visibility: visible;"><div class="login_tips">
    注册用户登录后才能发表评论，请 
    <a rel="nofollow" href="javascript:void(0);" class="underline" onclick="return login(&#39;commentform&#39;);">登录</a>
     或 
    <a rel="nofollow" href="javascript:void(0);" class="underline" onclick="return register();">注册</a>，
    <a href="https://www.cnblogs.com/">访问</a> 网站首页。
</div></div>
    <div class="ad_text_commentbox" id="ad_text_under_commentbox"></div>
    <div id="ad_t2"><a href="http://www.ucancode.com/index.htm" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-ucancode&#39;)">【推荐】超50万行VC++源码: 大型组态工控、电力仿真CAD与GIS源码库</a><br><a href="https://developer.aliyun.com/topic/offer/yunqi?utm_content=g_1000180856" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-阿里云offer5k&#39;)">【推荐】阿里云携近百家科技企业向你发来面试邀请</a><br><a href="https://brands.cnblogs.com/agora" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-声网专区&#39;)">【推荐】未知数的距离，毫秒间的传递，声网与你实时互动</a><br><a href="https://developer.aliyun.com/learning/trainingcamp/holo/1?utm_content=g_1000179015" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-阿里云Holo训练营&#39;)">【推荐】5天实战！技术大咖带你玩转实时数仓，赢定制T恤</a><br><a href="https://brands.cnblogs.com/huawei" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-华为专区&#39;)">【推荐】了不起的开发者，挡不住的华为，园子里的品牌专区</a><br><a href="https://developer.aliyun.com/article/727136?utm_content=g_1000088943" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T2-阿里云开发者社区&#39;)">【推荐】独家下载 |《大数据工程师必读手册》揭秘阿里如何玩转大数据</a><br></div>
    <div id="opt_under_post"></div>
    <div id="cnblogs_c1" class="c_ad_block">
        <div id="div-gpt-ad-1592365906576-0" style="width: 300px; height: 250px;" data-google-query-id="CNbmy4SE6OsCFfrKfAodCuoG5A"><div id="google_ads_iframe_/1090369/C1_0__container__" style="border: 0pt none; display: inline-block; width: 300px; height: 250px;"><iframe frameborder="0" src="./五种回归方法的比较 - Jin_liang - 博客园_files/container.html" id="google_ads_iframe_/1090369/C1_0" title="3rd party ad content" name="" scrolling="no" marginwidth="0" marginheight="0" width="300" height="250" data-is-safeframe="true" sandbox="allow-forms allow-popups allow-popups-to-escape-sandbox allow-same-origin allow-scripts allow-top-navigation-by-user-activation" data-google-container-id="1" style="border: 0px; vertical-align: bottom;" data-load-complete="true"></iframe></div></div>
    </div>
    <div id="under_post_news"><div class="recomm-block"><b>相关博文：</b><br>·  <a title="七种常见的回归分析" href="https://www.cnblogs.com/sumuncle/p/5647722.html" target="_blank" onclick="clickRecomItmem(5647722)">七种常见的回归分析</a><br>·  <a title="机器学习（七）—回归" href="https://www.cnblogs.com/ybjourney/p/4841366.html" target="_blank" onclick="clickRecomItmem(4841366)">机器学习（七）—回归</a><br>·  <a title="R--线性回归诊断（二）" href="https://www.cnblogs.com/runner-ljt/p/4583804.html" target="_blank" onclick="clickRecomItmem(4583804)">R--线性回归诊断（二）</a><br>·  <a title="Python回归分析五部曲（一）—简单线性回归" href="https://www.cnblogs.com/shujufenxi/p/9054439.html" target="_blank" onclick="clickRecomItmem(9054439)">Python回归分析五部曲（一）—简单线性回归</a><br>·  <a title="岭回归和lasso回归（转）" href="https://www.cnblogs.com/shixisheng/p/7252816.html" target="_blank" onclick="clickRecomItmem(7252816)">岭回归和lasso回归（转）</a><br>»  <a target="_blank" href="https://recomm.cnblogs.com/blogpost/9551759">更多推荐...</a><div id="cnblogs_t5"><a href="https://www.sheca.com/assets/wwx/page3.html?site=bokeyuan" target="_blank" onclick="ga(&#39;send&#39;, &#39;event&#39;, &#39;Link&#39;, &#39;click&#39;, &#39;T5-上海CA-大家签&#39;)">【推荐】电子签名认准大家签，上海CA权威认证</a></div></div></div>
    <div id="cnblogs_c2" class="c_ad_block">
        <div id="div-gpt-ad-1592366332455-0" style="width: 468px; height: 60px;" data-google-query-id="CKOAy4SE6OsCFfrKfAodCuoG5A"><div id="google_ads_iframe_/1090369/C2_0__container__" style="border: 0pt none;"><iframe id="google_ads_iframe_/1090369/C2_0" title="3rd party ad content" name="google_ads_iframe_/1090369/C2_0" width="468" height="60" scrolling="no" marginwidth="0" marginheight="0" frameborder="0" style="border: 0px; vertical-align: bottom;" data-google-container-id="2" data-load-complete="true" src="./五种回归方法的比较 - Jin_liang - 博客园_files/saved_resource.html"></iframe></div></div>
    </div>
    <div id="under_post_kb">
<div class="itnews c_ad_block">
    <b>最新 IT 新闻</b>:
    <br>
 ·          <a href="https://news.cnblogs.com/n/672797/" target="_blank">华为能够成功构建HMS生态，关键在这里</a>
        <br>
 ·          <a href="https://news.cnblogs.com/n/672802/" target="_blank">搅局的“巨鲸”，未止跌的科技股，动荡的大选季</a>
        <br>
 ·          <a href="https://news.cnblogs.com/n/672801/" target="_blank">沈腾语音包独家上线百度地图：专治不开心 太欠了</a>
        <br>
 ·          <a href="https://news.cnblogs.com/n/672800/" target="_blank">游戏开发商自曝新一代Switch正在开发中：支持4K分辨率游戏</a>
        <br>
 ·          <a href="https://news.cnblogs.com/n/672799/" target="_blank">《黑神话：悟空》游戏时长超15小时 敌人类型超百种</a>
        <br>
    » <a href="https://news.cnblogs.com/" title="IT 新闻" target="_blank">更多新闻...</a>
</div></div>
    <div id="HistoryToday" class="c_ad_block"></div>
    <script type="text/javascript">
        fixPostBody();
        deliverBigBanner();
setTimeout(function() { incrementViewCount(cb_entryId); }, 50);        deliverT2();
        deliverC1C2();
        loadNewsAndKb();
        loadBlogSignature();
LoadPostCategoriesTags(cb_blogId, cb_entryId);        LoadPostInfoBlock(cb_blogId, cb_entryId, cb_blogApp, cb_blogUserGuid);
        GetPrevNextPost(cb_entryId, cb_blogId, cb_entryCreatedDate, cb_postType);
        loadOptUnderPost();
        GetHistoryToday(cb_blogId, cb_blogApp, cb_entryCreatedDate);
    </script>
</div>
	</div><!--end: forFlow -->
	</div><!--end: mainContent 主体内容容器-->

	<div id="sideBar">
		<div id="sideBarMain">
			
<div id="sidebar_news" class="newsItem"><!--done-->
<h3 class="catListTitle">公告</h3>

<div id="blog-news">
    
    <div id="profile_block">
        昵称：
        <a href="https://home.cnblogs.com/u/jin-liang/">
            Jin_liang
        </a>
        <br>
        园龄：
        <a href="https://home.cnblogs.com/u/jin-liang/" title="入园时间：2018-03-07">
            2年6个月
        </a>
        <br>
        粉丝：
        <a href="https://home.cnblogs.com/u/jin-liang/followers/">
            31
        </a>
        <br>
        关注：
        <a href="https://home.cnblogs.com/u/jin-liang/followees/">
            1
        </a>
        <div id="p_b_follow">
<a href="javascript:void(0)" onclick="follow(&#39;e7b8b72d-1c91-4228-9a4a-08d581a6bd57&#39;)">+加关注</a></div>
        <script>getFollowStatus('e7b8b72d-1c91-4228-9a4a-08d581a6bd57');</script>
    </div>
</div>

</div>

<div id="sidebar_ad"></div>
			<div id="blog-calendar" style="">

<table id="blogCalendar" class="Cal" cellspacing="0" cellpadding="0" title="Calendar" border="0">
    <tbody>
        <tr>
            <td colspan="7">
                <table class="CalTitle" cellspacing="0" border="0">
                    <tbody>
                        <tr>
                            <td class="CalNextPrev">
                                <a href="javascript:void(0);" onclick="loadBlogCalendar(&#39;2020/08/14&#39;); return false;">&lt;</a>
                            </td>
                            <td align="center">2020年9月</td>
                            <td align="right" class="CalNextPrev">
                                <a href="javascript:void(0);" onclick="loadBlogCalendar(&#39;2020/10/14&#39;); return false;">&gt;</a>
                            </td>
                        </tr>
                    </tbody>
                </table>
            </td>
        </tr>
    <tr>
        <th class="CalDayHeader" align="center" abbr="日" scope="col">日</th>
        <th class="CalDayHeader" align="center" abbr="一" scope="col">一</th>
        <th class="CalDayHeader" align="center" abbr="二" scope="col">二</th>
        <th class="CalDayHeader" align="center" abbr="三" scope="col">三</th>
        <th class="CalDayHeader" align="center" abbr="四" scope="col">四</th>
        <th class="CalDayHeader" align="center" abbr="五" scope="col">五</th>
        <th class="CalDayHeader" align="center" abbr="六" scope="col">六</th>
    </tr>
            <tr>
                            <td class="CalOtherMonthDay" align="center">30</td>
                            <td class="CalOtherMonthDay" align="center">31</td>
                        <td class="" align="center">
                            1
                        </td>
                        <td class="" align="center">
                            2
                        </td>
                        <td class="" align="center">
                            3
                        </td>
                        <td class="" align="center">
                            4
                        </td>
                    <td class="CalWeekendDay" align="center">
                        5
                    </td>
            </tr>
                <tr>
                        <td class="CalWeekendDay" align="center">
                            6
                        </td>
                            <td class="" align="center">
                                7
                            </td>
                            <td class="" align="center">
                                8
                            </td>
                            <td class="" align="center">
                                9
                            </td>
                            <td class="" align="center">
                                10
                            </td>
                            <td class="" align="center">
                                11
                            </td>
                        <td class="CalWeekendDay" align="center">
                            12
                        </td>
                </tr>
                <tr>
                        <td class="CalWeekendDay" align="center">
                            13
                        </td>
                            <td class="CalTodayDay" align="center">
                                14
                            </td>
                            <td class="" align="center">
                                15
                            </td>
                            <td class="" align="center">
                                16
                            </td>
                            <td class="" align="center">
                                17
                            </td>
                            <td class="" align="center">
                                18
                            </td>
                        <td class="CalWeekendDay" align="center">
                            19
                        </td>
                </tr>
                <tr>
                        <td class="CalWeekendDay" align="center">
                            20
                        </td>
                            <td class="" align="center">
                                21
                            </td>
                            <td class="" align="center">
                                22
                            </td>
                            <td class="" align="center">
                                23
                            </td>
                            <td class="" align="center">
                                24
                            </td>
                            <td class="" align="center">
                                25
                            </td>
                        <td class="CalWeekendDay" align="center">
                            26
                        </td>
                </tr>
                <tr>
                        <td class="CalWeekendDay" align="center">
                            27
                        </td>
                            <td class="" align="center">
                                28
                            </td>
                            <td class="" align="center">
                                29
                            </td>
                            <td class="" align="center">
                                30
                            </td>
                            <td class="CalOtherMonthDay" align="center">
                                1
                            </td>
                            <td class="CalOtherMonthDay" align="center">
                                2
                            </td>
                        <td class="CalOtherMonthDay" align="center">
                            3
                        </td>
                </tr>
                <tr>
                        <td class="CalOtherMonthDay" align="center">
                            4
                        </td>
                            <td class="CalOtherMonthDay" align="center">
                                5
                            </td>
                            <td class="CalOtherMonthDay" align="center">
                                6
                            </td>
                            <td class="CalOtherMonthDay" align="center">
                                7
                            </td>
                            <td class="CalOtherMonthDay" align="center">
                                8
                            </td>
                            <td class="CalOtherMonthDay" align="center">
                                9
                            </td>
                        <td class="CalOtherMonthDay" align="center">
                            10
                        </td>
                </tr>
    </tbody>
</table></div><script>loadBlogDefaultCalendar();</script>
			
			<div id="leftcontentcontainer">
				<div id="blog-sidecolumn">
<!-- 搜索 -->
<div id="sidebar_search" class="sidebar-block">
    <div id="sidebar_search" class="mySearch">
        <h3 class="catListTitle">搜索</h3>
        <div id="sidebar_search_box">
            <div id="widget_my_zzk" class="div_my_zzk">
                <input type="text" id="q" onkeydown="return zzk_go_enter(event);" class="input_my_zzk">&nbsp;<input onclick="zzk_go()" type="button" value="找找看" id="btnZzk" class="btn_my_zzk">
            </div>
            <div id="widget_my_google" class="div_my_zzk">
                <input type="text" name="google_q" id="google_q" onkeydown="return google_go_enter(event);" class="input_my_zzk">&nbsp;<input onclick="google_go()" type="button" value="谷歌搜索" class="btn_my_zzk">
            </div>
        </div>
    </div>
</div>

<!-- 常用链接 -->
<div id="sidebar_shortcut" class="sidebar-block">
    <div class="catListLink">
<h3 class="catListTitle">
常用链接
</h3>
<ul>
    
<li><a href="https://www.cnblogs.com/jin-liang/p/" title="我的博客的随笔列表">我的随笔</a></li>
<li><a href="https://www.cnblogs.com/jin-liang/MyComments.html" title="我的发表过的评论列表">我的评论</a></li>
<li><a href="https://www.cnblogs.com/jin-liang/OtherPosts.html" title="我评论过的随笔列表">我的参与</a></li>
<li><a href="https://www.cnblogs.com/jin-liang/RecentComments.html" title="我的博客的评论列表">最新评论</a></li>
<li><a href="https://www.cnblogs.com/jin-liang/tag/" title="我的博客的标签列表">我的标签</a></li>

</ul>
</div>


</div>

<!-- 最新随笔 -->
<div id="sidebar_recentposts" class="sidebar-block">
    <div class="catListEssay">
<h3 class="catListTitle">最新随笔</h3>
    <ul>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9987661.html">1.python中zip()函数的用法</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9987541.html">2.enumerate用法总结</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9884411.html">3.数据分析框架：实现99%准确率</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9863987.html">4.一份详细的 Matplotlib入门指导</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9852321.html">5.python做单因素方差分析</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9747246.html">6.Keras开发一个神经网络</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9746313.html">7.深度学习介绍及简单应用</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9743518.html">8.概率图模型导论</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9717651.html">9.超平面与法向量</a>

                </li>
                <li>
                    
<a href="https://www.cnblogs.com/jin-liang/p/9713118.html">10.感知机</a>

                </li>
    </ul>
</div>


</div>


<!-- 我的标签 -->
<div id="sidebar_toptags" class="sidebar-block">
    
</div>

<!-- 积分与排名 -->


<!-- 随笔分类、随笔档案、文章分类、新闻分类、相册、链接 -->
<div id="sidebar_categories">
    
        <div id="sidebar_postcategory" class="catListPostCategory sidebar-block">
            <h3 class="catListTitle">
                
随笔分类



            </h3>


            <ul>

                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1197006.html" rel="" target="">
    eviews软件操作方法(1)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1313559.html" rel="" target="">
    kaggle案例(1)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1197001.html" rel="" target="">
    python常用小技巧(5)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1197004.html" rel="" target="">
    R语言学习之路(2)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1306574.html" rel="" target="">
    概率图模型(1)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1197005.html" rel="" target="">
    机器学习之路(16)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1205552.html" rel="" target="">
    金融应用(4)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1296127.html" rel="" target="">
    深度学习(2)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1212913.html" rel="" target="">
    数据可视化(3)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1309751.html" rel="" target="">
    数学(1)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1266259.html" rel="" target="">
    数学工具(5)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/category/1308595.html" rel="" target="">
    统计方法(1)
</a>
 

                        </li>

            </ul>


        </div>
        <div id="sidebar_postarchive" class="catListPostArchive sidebar-block">
            <h3 class="catListTitle">
                
随笔档案



            </h3>


            <ul>

                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/archive/2018/11.html" rel="" target="">
    2018年11月(3)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/archive/2018/10.html" rel="" target="">
    2018年10月(5)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/archive/2018/09.html" rel="" target="">
    2018年9月(10)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/archive/2018/08.html" rel="" target="">
    2018年8月(9)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/archive/2018/07.html" rel="" target="">
    2018年7月(3)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/archive/2018/05.html" rel="" target="">
    2018年5月(7)
</a>
 

                        </li>
                        <li>
                            
<a href="https://www.cnblogs.com/jin-liang/archive/2018/04.html" rel="" target="">
    2018年4月(5)
</a>
 

                        </li>

            </ul>


        </div>

</div>

<!-- 最新评论 -->
<div id="sidebar_recentcomments" class="sidebar-block">
    <div class="catListComment">
<h3 class="catListTitle">最新评论</h3>

	<div class="RecentCommentBlock">
        <ul>
                    <li class="recent_comment_title"><a href="https://www.cnblogs.com/jin-liang/p/9064020.html">1. Re:R语言主成分分析（PCA）</a></li>
                    <li class="recent_comment_body"><p>请问你的碎石图前三个主成分特征值都大于1，你的碎石图为什么选了前两个主成分？</p>
</li>
                    <li class="recent_comment_author">--chaos924</li>
                    <li class="recent_comment_title"><a href="https://www.cnblogs.com/jin-liang/p/9064020.html">2. Re:R语言主成分分析（PCA）</a></li>
                    <li class="recent_comment_body"><p>假如我有17个变量，为什么碎石图横坐标只显示了10个？？</p>
</li>
                    <li class="recent_comment_author">--好心情12</li>
                    <li class="recent_comment_title"><a href="https://www.cnblogs.com/jin-liang/p/9064020.html">3. Re:R语言主成分分析（PCA）</a></li>
                    <li class="recent_comment_body"><p>请问主成分散点图能具体解释一下吗</p>
</li>
                    <li class="recent_comment_author">--好心情12</li>
                    <li class="recent_comment_title"><a href="https://www.cnblogs.com/jin-liang/p/9521061.html">4. Re:k均值聚类</a></li>
                    <li class="recent_comment_body">你好 能再发一下参考数据吗，百度网盘分享取消了，491292081@qq.com</li>
                    <li class="recent_comment_author">--程序猿830</li>
                    <li class="recent_comment_title"><a href="https://www.cnblogs.com/jin-liang/p/9064020.html">5. Re:R语言主成分分析（PCA）</a></li>
                    <li class="recent_comment_body">请问有原数据吗<br>jiaxinwei666@qq.com<br>感谢🙇‍</li>
                    <li class="recent_comment_author">--jiaxinwei</li>
        </ul>
    </div>
</div>


</div>



<!-- 阅读排行榜 -->
<div id="sidebar_topviewedposts" class="sidebar-block">
    <div class="catListView">
<h3 class="catListTitle">阅读排行榜</h3>
	<div id="TopViewPostsBlock">
        <ul style="word-break:break-all">
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/9064020.html">
                            1. R语言主成分分析（PCA）(34505)
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/8922832.html">
                            2. R语言for循环(17075)
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/9537539.html">
                            3. 解决异方差问题--加权最小二乘法(14480)
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/9852321.html">
                            4. python做单因素方差分析(12046)
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/9551759.html">
                            5. 五种回归方法的比较(11562)
                        </a>
                    </li>
        </ul>
    </div>
</div>


</div>

<!-- 评论排行榜 -->
<div id="sidebar_topcommentedposts" class="sidebar-block">
    <div class="catListFeedback">
<h3 class="catListTitle">评论排行榜</h3>
	<div id="TopFeedbackPostsBlock">
        <ul style="word-break:break-all">
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/9064020.html">
                            1. R语言主成分分析（PCA）(4)
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/9638197.html">
                            2. 决策树（四）决策树调参(2)
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/9863987.html">
                            3. 一份详细的 Matplotlib入门指导(1)
                        </a>
                    </li>
                    <li>
                        <a href="https://www.cnblogs.com/jin-liang/p/9521061.html">
                            4. k均值聚类(1)
                        </a>
                    </li>
        </ul>
    </div>
</div>


</div>

<!-- 推荐排行榜 -->
<div id="sidebar_topdiggedposts" class="sidebar-block">
    
<div id="topdigg_posts_wrap">
    <div class="catListView">
        <h3 class="catListTitle">推荐排行榜</h3>
        <div id="TopDiggPostsBlock">
            <ul style="word-break: break-all">
                        <li>
                            <a href="https://www.cnblogs.com/jin-liang/p/9011771.html">
                                1. seaborn 数据可视化(二）带有类别属性的数据可视化(1)
                            </a>
                        </li>
                        <li>
                            <a href="https://www.cnblogs.com/jin-liang/p/9064020.html">
                                2. R语言主成分分析（PCA）(1)
                            </a>
                        </li>
                        <li>
                            <a href="https://www.cnblogs.com/jin-liang/p/9393361.html">
                                3. python数学工具（一）(1)
                            </a>
                        </li>
                        <li>
                            <a href="https://www.cnblogs.com/jin-liang/p/9539622.html">
                                4. 如何判别模型的优劣？(1)
                            </a>
                        </li>
                        <li>
                            <a href="https://www.cnblogs.com/jin-liang/p/9551759.html">
                                5. 五种回归方法的比较(1)
                            </a>
                        </li>
            </ul>
        </div>
    </div>
</div>
</div></div>
                    <script>loadBlogSideColumn();</script>
			</div>
			
		</div><!--end: sideBarMain -->
	</div><!--end: sideBar 侧边栏容器 -->
	<div class="clear"></div>
	</div><!--end: main -->
	<div class="clear"></div>
	<div id="footer">
		<!--done-->
Copyright © 2020 Jin_liang
<br><span id="poweredby">Powered by .NET Core on Kubernetes</span>



	</div><!--end: footer -->
</div><!--end: home 自定义的最大容器 -->


    


<iframe id="google_osd_static_frame_756475605514" name="google_osd_static_frame" style="display: none; width: 0px; height: 0px;" src="./五种回归方法的比较 - Jin_liang - 博客园_files/saved_resource(1).html"></iframe></body></html>